<!DOCTYPE html>
<html>
<head>
	<title>AI</title>
	<link rel="stylesheet" type="text/css" href="style.css">
	<link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Press+Start+2P&display=swap" rel="stylesheet">
	<script src="https://kit.fontawesome.com/4df6340708.js" crossorigin="anonymous"></script>
</head>
<body>
	<script src="index.js"></script>
	<div class="container"><h2>AI</h2><h6> Artificial Intelligence</h6></div>
	
		<h1>What is AI ?</h1>
		<p id="p1">
			<br>
			<font size="4">
			AI is revolutionizing our world by automating tasks once done by humans, increasing<strong> efficiency</strong> and <strong>productivity</strong>.<br> <strong> Machine</strong> and <strong> deep learning </strong> empower algorithms to learn from <em>data</em>,<em> classify</em>, and <em>predict</em>.<br> AI can process<strong> diverse data types</strong> such as <em>images</em>, <em>video</em>,<em> software code</em>, and<em> molecular structures</em>. ChatGPT is a significant milestone for generative AI. Prioritizing responsible AI practices is crucial to ensure everyone benefits from this powerful technology.
			<br>
			<strong>
			<div class="container2">
			<img id ="AI" src="https://img.pikbest.com/background/20220119/ai-artificial-intelligence-starry-sky-portrait-blue-technology-banner_6231445.jpg!sw800" alt = "Not able to load" title=" AI(Artificial Intelligence)" height=350 width=1250>
			</div>
			<br>

			<a href="https://www.ibm.com/topics/artificial-intelligence">Acknowledgement and referrence </a>
			</strong>

		</p>
		<br>
		<br>
		<h1>Neural network</h1>
		<p id ="p2">
			<br>
				<strong>A neural network</strong>, also known as an <strong>artificial neural network</strong> or <strong>neural net</strong> (abbreviated ANN or NN), is an <em>advanced</em> and <em>complex model</em> that is based on the <strong>biological neural networks found in animal brains</strong>. It consists of a series of connected units or nodes that simulate the neurons in the brain. These nodes are linked by edges that resemble the synapses in the brain. Each node receives signals from connected neurons, processes them, and sends a signal to other connected neurons. The <strong>signal</strong> transmitted is a <em>real number</em> that is computed by a <em>non-linear function of the sum of inputs</em>, which is called the <strong>activation function</strong>. The neurons and edges in the network have a weight that adjusts as learning progresses. This weight either increases or decreases the strength of the signal at a connection. 
				<br>
				<br>
				All the neurons in a neural network are organized into layers, and different layers may perform different transformations on their inputs. Signals travel from the <strong>first layer (the input layer)</strong> to the <strong>last layer (the output layer)</strong>, possibly passing through <strong> multiple intermediate layers (hidden layers)</strong>. <em>If a network has at least 2 hidden layers, it is called a</em><strong> deep neural network</strong>. 
				<br>
				<br>
				Artificial neural networks are used for predictive modeling, adaptive control, and other applications where they can be trained via a dataset. They are capable of learning from experience and can derive conclusions from a complex and seemingly unrelated set of information. Neural networks are a powerful tool in the field of artificial intelligence and have become a popular choice for solving problems in various domains.
				<br>
				<br>
			<br>
			<strong>
			<a href="https://en.wikipedia.org/wiki/Neural_network_(machine_learning)">Acknowledgement and referrence </a>
			</strong>
			<br>
		</p>
		<h1>Deep Neural Networks</h1>
		<p>	
			<div class="container3">
				<img id ="DNN1" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQqEpH45aoOmFV-TmM0q5d3zF2DD5CVIHFIBC38cDya-Q&s" alt = "Not able to load"
				title="Deep Neural Network(DNN)" height=300 width=500>
				</div>
			<br>
			<strong>A deep neural network (DNN)</strong> is a type of <strong>artificial neural network (ANN)</strong> that has <strong>multiple hidden layers located between the input and output layers</strong>. Similar to <em>shallow ANNs</em>, DNNs can model  <strong>complex non-linear relationships between inputs and outputs</strong>. 
			<br>
			The main purpose of a neural network is to <strong>receive a set of inputs</strong>, <strong>perform progressively complex calculations on them</strong>, and <strong>provide an output that can solve real-world problems</strong>, such as <strong>classification</strong>.
			<br>
			A deep network consists of an input, an output, and a <em>sequential flow of data</em>. Neural networks are widely used in     <strong>supervised learning</strong>and <strong>reinforcement learning problems</strong>. These networks are based on a set of layers that are <strong>interconnected</strong>. 
			<br>
			<em>In deep learning, the number of hidden layers can be large, sometimes numbering in the thousands, and are mostly non-linear. Deep learning models produce much better results than normal machine learning networks. </em
			<br>

			<br>
			<strong>
			<a href="https://www.tutorialspoint.com/python_deep_learning/python_deep_learning_deep_neural_networks.htm">Acknowledgement and referrence </a>
			<br>
			</strong>

		</p>
	 	<h1 id = "NeuralNetworks">Logic and understanding of neural networks	</h1>
	 	<p>
		 	<br>
		 	<strong>The neuron is the atomic unit of a neural network</strong>. Given an input, it provides the output and passes that output as an input to the <strong>subsequent layer</strong>. A neuron can be thought of as a combination of 2 parts:
		 	<br>
			<img src ="G:\HTML\HTML Projects\images\output-onlinepngtools.png " alt = "Not able to load"
			title="Neuron" height=150 width=300 >
			<br>
			The first part computes <strong>the output Z</strong>, using the <em>inputs</em> and the <em> weights</em>.
			<br>
			The second part performs the activation on Z to give out the final output A of the neuron.
			The Hidden Layer
			<br>
			The hidden layer comprises of various neurons, each of which performs the above 2 calculations. The 4 neurons present in the hidden layer of our shallow neural network compute the following:
			<br>
			<img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*n6VFcapcbmSwR3kDOOCjNA.png" alt = "Not able to load"
			title="Neuron" height=150 width=300>
			<br>
			<strong>
			In the above equations,
			<br>
			The superscript number [i] denotes the layer number and the subscript number j denotes the neuron number in a particular layer.
			<br>
			X is the input vector consisting of 3 features.
			<br>
			W[i]j is the weight associated with neuron j present in the layer i.
			<br>
			b[i]j is the bias associated with neuron j present in the layer i.
			<br>
			Z[i]j is the intermediate output associated with neuron j present in the layer i.
			<br>
			A[i]j is the final output associated with neuron j present in the layer i.
			<br>
			Sigma is the sigmoid activation function. Mathematically it is defined as:
			<br>
			</strong>
			<img src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*s5aP_gj-4Yp4M43rdJOldw.png" alt = "Not able to load"
			title="Neuron" height=75 width=300>
			<br>
			As we can see, the above 4 equations seem redundant. Therefore we will <strong>vectorize</strong> them as:
			<br>
			<br>
			<img src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*Jray1MUI1EJU-W-rGUPPZA.png" alt = "Not able to load"
			title="Neuron" height=100 width=300>
			<br>
			The first equation computes <strong>all the intermediate outputs Z in single matrix multiplication</strong>.
			<br>
			The second equation computes <strong>all the activations A in single matrix multiplication</strong>.
			<br>
			<strong>
			<a href="https://towardsdatascience.com/shallow-neural-networks-23594aa97a5">Bibliography </a>
			</strong>
			<br>
		</p>
		<h1>Shallow Neural Networks</h1>
		<p>
			<br>
			A <strong>shallow neural network</strong> is a type of artificial neural network that has <strong>only one</strong> or <strong>a few hidden layers between the input and output layers</strong>. Shallow neural networks are <em>simpler</em>, <em>easier to train</em>, and <em>more computationally efficient than deep neural networks</em>, which may have thousands of hidden units in dozens of layers. Shallow networks are typically used for <strong>simpler tasks</strong> such as <strong>linear regression</strong>, <strong>binary classification</strong>, or <strong>low-dimensional feature extraction</strong>.
			<br>
            It's worth noting that,technically <em>a neural network with more than one hidden layer is not considered a shallow neural network</em>. However, <strong>in some cases</strong>, a <em>neural network with two or three hidden layers, each with a small number of hidden units and simple connectivity between them, may still produce straightforward outputs and be considered a "shallow" network.</em>
			<br>
			<strong>
			<a href="https://mriquestions.com/shallow-networks.html">Acknowledgement and referrence </a>
			</strong>
			<br>
		</p>
		<h1>Machine Learning </h1>
		<p>
			<div class="container4">
				<img id ="Machine Learning" src="https://cdn-icons-png.flaticon.com/512/2083/2083213.png" alt = "Not able to load"
				title="Machine Learning" height=250 width=350>
				</div>
		 	<br>
		 	<strong>Machine Learning</strong> is a subfield of Artificial Intelligence that uses <strong>algorithms to detect patterns in datasets and make predictions without explicit programming</strong>. It is applied in various areas such as <em>image and speech recognition, natural language processing, fraud detection, and automated tasks</em>. Machine Learning models are also used to power <em>autonomous vehicles, drones, and robots, making them intelligent and adaptable</em>.
		 	<br>
		 	<strong>Arthur Samuel</strong>, a computer scientist, and pioneer in the field of <strong>artificial intelligence (AI)</strong> and <strong>computer gaming</strong>, is credited with coining the term <strong>"Machine Learning"</strong> in 1959. He defined Machine Learning as a <em>"Field of study that gives computers the capability to learn without being explicitly programmed."</em> In other words, <strong>Machine Learning (ML) is a subfield of AI that focuses on creating algorithms that can learn and improve from experience, without being explicitly programmed.</strong> 
		 	<br>
			In simple terms, ML involves <strong>automating</strong> and <strong>improving the learning process of computers based on their experiences without any human assistance</strong>. This is done by feeding <em>good-quality data into the system and then training the machine-learning models using different algorithms</em>. The choice of algorithms depends on <strong>what type of data we have and what kind of task we are trying to automate</strong>. 
			<br>
			The process of machine learning typically starts with <strong>data collection and preprocessing</strong>. This involves <em>gathering data from various sources, cleaning, and transforming it into a format that can be easily understood by machine learning algorithms</em>. The next step is to select an appropriate machine learning algorithm and train it on the data. This involves feeding the algorithm with a set of training data and allowing it to learn from this data to make predictions on new, unseen data. 
			<br>
			There are many different types of machine learning algorithms, including supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning. Each type of algorithm is designed to solve a specific type of problem, such as classification, regression, clustering, or prediction. 
			<br>
			Machine learning has many practical applications in a variety of fields, from healthcare and finance to marketing and cybersecurity. It is used to detect fraud, diagnose diseases, predict stock prices, and even create self-driving cars. With the increasing availability of data and advances in computing power, the potential for machine learning to transform our world is enormous.
			<br>

			<strong>
			<a href="https://www.geeksforgeeks.org/ml-machine-learning/">Acknowledgement and referrence </a>
			</strong>
			<br>
		</p>
	 	<h1>Deep Learning </h1>	
		<h3>And how is it Associated with Artificial Intelligence(AI)</h3>
		<p>
		 	<strong>Deep learning</strong> is a crucial component of artificial intelligence (AI) applications and services. It is a powerful technology that <strong>enhances automation and adds intelligence to existing AI-enabled products</strong>. Deep learning is the branch of AI that <strong>enables analytical and physical tasks to be performed without human intervention</strong>.
		 	<br>
			Deep learning involves the use of complex machine learning techniques that help computers to learn and respond in ways that are similar to humans. It is a driving force behind many innovations such as driverless cars, hands-free speakers, and voice recognition in phones, tablets, TVs, and watches.
			<br>
			In deep learning, computers learn to perform tasks by using data inputs such as images, text, or sound. These models can achieve super-accurate results that are often even better and more efficient than those achieved by human beings. Deep learning models use large datasets that require high computational power. They respond accurately by using a neural network with multiple layers, which is similar to the structure of the human brain.
			<br>
			To sum it up, deep learning is a subset of machine learning, which in turn is a subset of artificial intelligence. It is a powerful tool that enables computers to learn and respond in ways that are similar to humans, and it is driving many of the most exciting innovations in the field of AI today.
			<br>
			<br>
			<strong>
			<a href="https://www.forbes.com/advisor/in/business/software/what-is-deep-learning-ai/">Acknowledgement and referrence </a>
			</strong>
			<br>
		</p>
		<h1>Natural Language Processing</h1>
		<p>
			<strong>Natural language processing</strong>, or NLP, <strong>combines computational linguistics—rule-based modeling of human language—with statistical and machine learning models to enable computers and digital devices to recognize, understand and generate text and speech</strong>.
			<br>
			<ol>A branch of artificial intelligence (AI), NLP lies at the heart of applications and devices that can

			<li>translate text from one language to another</li>
			<li>respond to typed or spoken commands</li>
			<li>recognize or authenticate users based on voice</li>
			<li>summarize large volumes of text</li>
			<li>assess the intent or sentiment of text or speech</li>
			<li>generate text or graphics or other content on demand
			often in real time.</li> 
			</ol>
			<br>
			Today most people have interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences. But NLP also plays a growing role in enterprise solutions that help streamline and automate business operations, increase employee productivity, and simplify mission-critical business processes.
			<br>
			<strong>
			<br>
			<a href="https://www.ibm.com/topics/natural-language-processing">Bibliography </a>
			<br>
			<br>
			</strong>
			<br>
		</p>
		<h1>Cognitive Computing</h1>
		<p>
			<strong>Cognitive computing</strong> is a cutting-edge technology that <strong> humans in their decision-making processes</strong>. It is a <strong> of artificial intelligence that goes beyond basic rule-based programming and employs advanced algorithms to simulate human intelligence</strong>. Unlike traditional AI systems that rely on pre-programmed rules to solve problems, cognitive computing systems use machine learning and natural language processing to learn from data, identify patterns, and make predictions.
			<br>
			Cognitive computing has a more ambitious goal than AI, which is to create algorithms that can mimic the human brain's reasoning process, including perception, learning, and problem-solving. This means that cognitive computing systems can adapt to new situations and learn from experience, making them more flexible and versatile than traditional AI systems.
			<br>
			As a result, cognitive computing is being used in a wide range of applications, from healthcare and finance to marketing and customer service. For instance, cognitive computing can help doctors diagnose diseases more accurately, financial analysts make better investment decisions, marketers personalize their campaigns, and customer service agents provide more personalized support.
			<br>
			<br>
			<br>
			<a href="https://www.techtarget.com/searchenterpriseai/definition/cognitive-computing#:~:text=The%20term%20cognitive%20computing%20is%20typically%20used%20to%20describe%20AI,person's%20ability%20to%20solve%20problems.">Acknowledgement and Bibliography </a>	
		</p>
		<h1>Computer Vision</h1>
		<p>
			Computer vision is a field of study within artificial intelligence (AI) that focuses on enabling computers to Intercept and extract information from images and videos, in a manner similar to human vision. It involves developing algorithms and techniques to extract meaningful information from visual inputs and make sense of the visual world.
			<br>
			<a href="https://www.geeksforgeeks.org/computer-vision/">Bibliography
		</p>
		<!-- !the animated pictures are not all completed -->
		</font>
</body>
</html> 